{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57aa4fe",
   "metadata": {},
   "source": [
    "## Business Problem Statement Understanding: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22bae7",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94231f6",
   "metadata": {},
   "source": [
    "Build a Car Price prediction using Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02142a23",
   "metadata": {},
   "source": [
    "UsedCar.com, a well-known business, is an online marketplace that enables customers to sell or buy a vehicle throughout Germany. When they receive a request to sell an automobile, one of their sales representatives goes to the client's location to gather all the information, including Brand Name, Model Name, year, KMS Driven, and Fuel Type. Once you return to the office, the backend staff will analyze the information that the salesperson supplied and forecast the car's current pricing. The salesperson then visits the client once more to discuss the price. \n",
    "\n",
    "They find the process to be extremely time-consuming, so they resolve to make it intelligent, automated, and clever. They therefore decide to use a system that will forecast the client's pricing. As a result, the client will be pleased with the special response and be able to sell or buy a car through UsedCar.com, increasing the company's share price by 35% after making the procedure quick and creative.\n",
    "\n",
    "They therefore made the decision to create a website that will display the current pricing of the automobile based on user inputs such as Brand Name, Model Name, year, KMS Driven, and Fuel type. Here, they plan to employ a machine learning algorithm that will automatically forecast the price of the car based on its characteristics.\n",
    "\n",
    "For that, our domain experts and data analysts met with the client at Quikr's headquarters to better grasp their problem and expectations. So they asked the client directly for the necessary information.\n",
    "\n",
    "    1) name        >> Name of the car (Including Model Number & version)\t\n",
    "    \n",
    "    2) company\t >> Car Brand\n",
    "    \n",
    "    3) year\t     >> Year of the model\n",
    "    \n",
    "    4) Price \t   >> Present price of the Car \t\n",
    "    \n",
    "    5) kms_driven  >> Kilometer driven by the Car\t\n",
    "    \n",
    "    6) fuel_type   >> Whether Car runs on Petrol/Diesel/LPG\n",
    "\n",
    "In order to detect patterns in the dataset using the aforementioned features and attributes supplied by the client, the client wishes to train a machine learning pipeline. Once the user provides new information, our ML model will then automatically predict the price of the car."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f340b",
   "metadata": {},
   "source": [
    "As we are aware, Price exhibits consistent behavior. It is referred to as \"Regression.\" Therefore, the price prediction for cars falls within the \"Regression\" linked kind. So, in order to forecast the cost of the car, we are utilizing the \"Regression Algorithm.\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "004b8628",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62d7d0ca",
   "metadata": {},
   "source": [
    "### Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62bc0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    " \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078352ad",
   "metadata": {},
   "source": [
    "Here, we have loaded 3 types of Libraries\n",
    "\n",
    "a) Inbuilt Library\n",
    "\n",
    "\n",
    "b) Third-Party Library\n",
    "\n",
    "\n",
    "c) Skitlearn Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180141f",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b1c39",
   "metadata": {},
   "source": [
    "According to client inputs, our domain experts and data analysts team created the dataset in.CSV format. Additionally, we will train our machine learning (ML) algorithm using the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b59d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('quikr_car.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297548cc",
   "metadata": {},
   "source": [
    "Load the dataset files with csv extension from the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf98d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hyundai Santro Xing XO eRLX Euro III</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2007</td>\n",
       "      <td>80,000</td>\n",
       "      <td>45,000 kms</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mahindra Jeep CL550 MDI</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2006</td>\n",
       "      <td>4,25,000</td>\n",
       "      <td>40 kms</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maruti Suzuki Alto 800 Vxi</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2018</td>\n",
       "      <td>Ask For Price</td>\n",
       "      <td>22,000 kms</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai Grand i10 Magna 1.2 Kappa VTVT</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2014</td>\n",
       "      <td>3,25,000</td>\n",
       "      <td>28,000 kms</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford EcoSport Titanium 1.5L TDCi</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2014</td>\n",
       "      <td>5,75,000</td>\n",
       "      <td>36,000 kms</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Ta</td>\n",
       "      <td>Tara</td>\n",
       "      <td>zest</td>\n",
       "      <td>3,10,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Tata Zest XM Diesel</td>\n",
       "      <td>Tata</td>\n",
       "      <td>2018</td>\n",
       "      <td>2,60,000</td>\n",
       "      <td>27,000 kms</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Mahindra Quanto C8</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2013</td>\n",
       "      <td>3,90,000</td>\n",
       "      <td>40,000 kms</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Honda Amaze 1.2 E i VTEC</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2014</td>\n",
       "      <td>1,80,000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Chevrolet Sail 1.2 LT ABS</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>2014</td>\n",
       "      <td>1,60,000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name    company  year          Price  \\\n",
       "0      Hyundai Santro Xing XO eRLX Euro III    Hyundai  2007         80,000   \n",
       "1                   Mahindra Jeep CL550 MDI   Mahindra  2006       4,25,000   \n",
       "2                Maruti Suzuki Alto 800 Vxi     Maruti  2018  Ask For Price   \n",
       "3    Hyundai Grand i10 Magna 1.2 Kappa VTVT    Hyundai  2014       3,25,000   \n",
       "4          Ford EcoSport Titanium 1.5L TDCi       Ford  2014       5,75,000   \n",
       "..                                      ...        ...   ...            ...   \n",
       "887                                      Ta       Tara  zest       3,10,000   \n",
       "888                     Tata Zest XM Diesel       Tata  2018       2,60,000   \n",
       "889                      Mahindra Quanto C8   Mahindra  2013       3,90,000   \n",
       "890                Honda Amaze 1.2 E i VTEC      Honda  2014       1,80,000   \n",
       "891               Chevrolet Sail 1.2 LT ABS  Chevrolet  2014       1,60,000   \n",
       "\n",
       "     kms_driven fuel_type  \n",
       "0    45,000 kms    Petrol  \n",
       "1        40 kms    Diesel  \n",
       "2    22,000 kms    Petrol  \n",
       "3    28,000 kms    Petrol  \n",
       "4    36,000 kms    Diesel  \n",
       "..          ...       ...  \n",
       "887         NaN       NaN  \n",
       "888  27,000 kms    Diesel  \n",
       "889  40,000 kms    Diesel  \n",
       "890      Petrol       NaN  \n",
       "891      Petrol       NaN  \n",
       "\n",
       "[892 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fa0632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Rows:  892\n",
      "No. of Columns:  6\n"
     ]
    }
   ],
   "source": [
    "print('No. of Rows: ',df.shape[0])\n",
    "print('No. of Columns: ',df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341aa68",
   "metadata": {},
   "source": [
    "### Spliting the dataset into Training dataset and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3274109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train size:  (713, 6)\n",
      "df_test size:  (179, 6)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df,test_size=0.2,random_state=20)\n",
    "\n",
    "print('df_train size: ',df_train.shape)\n",
    "print('df_test size: ',df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f951ced",
   "metadata": {},
   "source": [
    "To prevent the problem of data leakage, we divided the data at the very beginning of the task. When the information that we use to train a machine learning algorithm is present in the training data, this is referred to as data leakage in machine learning. As a result, we divide the testing data from the training data (used to train the model) (To predict the data outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cda44a",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f534c2",
   "metadata": {},
   "source": [
    "Here, We have performed the data exploration task on the df_train (Training) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f548fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 713 entries, 812 to 355\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        713 non-null    object\n",
      " 1   company     713 non-null    object\n",
      " 2   year        713 non-null    object\n",
      " 3   Price       713 non-null    object\n",
      " 4   kms_driven  667 non-null    object\n",
      " 5   fuel_type   665 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 39.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f526bc",
   "metadata": {},
   "source": [
    "df_train.info() >> This gives us information about the attributes, data type of the attribute, information about the null values of the attributes, memory size of the class which is 39.0+ KB.\n",
    "\n",
    "We have observed that all the attributes are having 'Object' dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5ea16",
   "metadata": {},
   "source": [
    "Here, We will try to find out the Explicit and Implicit Missing values in our Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc38685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89ca2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Honda City                                11\n",
       "Honda Amaze                               10\n",
       "Maruti Suzuki Dzire                        9\n",
       "Maruti Suzuki Alto 800 Lxi                 7\n",
       "Mahindra Jeep CL550 MDI                    6\n",
       "                                          ..\n",
       "Maruti Suzuki Esteem LXi BS III            1\n",
       "Tata Indica V2 Xeta e GLE                  1\n",
       "all paper updated tata indica v2 and u     1\n",
       "selling car Ta                             1\n",
       "Hyundai Verna                              1\n",
       "Name: name, Length: 448, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2ead3",
   "metadata": {},
   "source": [
    "df_train['name'].value_counts() >> Here, we are getting value count of each samples present in the ['name'] attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32d69f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TATA INDI', 'Mahindra Bolero DI',\n",
       "       'Mitsubishi Pajero Sport Limited Edition',\n",
       "       'Maruti Suzuki Ertiga ZXI Plus', 'Sale tata',\n",
       "       'Ford Fiesta SXi 1.6 ABS', 'Nissan Terrano XL D Plus',\n",
       "       'Hyundai i20 Magna', 'Tata Nano', 'Maruti Suzuki Wagon R',\n",
       "       'Hyundai Santro Xing', 'Maruti Suzuki Swift VXi 1.2 ABS BS IV',\n",
       "       'Maruti Suzuki Swift Vdi BSIII', 'Hyundai i20 Sportz 1.2',\n",
       "       'Hyundai Santro AE GLS Audio', 'Datsun Redi GO', 'Toyota Corolla',\n",
       "       'Maruti Suzuki Zen Estilo LXI Green CNG',\n",
       "       'Maruti Suzuki Dzire LDI', 'Hyundai i20 Active 1.4L SX O',\n",
       "       'Maruti Suzuki Zen LXi BSII', 'Mahindra Jeep CL550 MDI',\n",
       "       'Toyota Corolla Altis', 'Hyundai i20 Active 1.2 SX',\n",
       "       'Maruti Suzuki Alto 800 Lxi', 'Ta', 'Tata Indigo CS GLS',\n",
       "       'Tata Indigo eCS LX TDI BS III',\n",
       "       'Maruti Suzuki Swift Select Variant',\n",
       "       'Tata Sumo Victa EX 10 by 7 Str BSIII', 'Honda City 1.5 V MT',\n",
       "       'Hyundai Grand i10 Magna 1.2 Kappa VTVT',\n",
       "       'Toyota Corolla Altis 1.8 GL', 'Mahindra TUV300 T8',\n",
       "       'Renault Lodgy', 'Tata Indica V2 eLS',\n",
       "       'Ford EcoSport Titanium 1.5L TDCi',\n",
       "       'Ford EcoSport Ambiente 1.5L TDCi', 'Honda Amaze', 'Hyundai Eon',\n",
       "       'Renault Duster 85 PS RxE Diesel', '9 SEATER MAHINDRA BOL',\n",
       "       'Hyundai i20 Asta 1.2', 'Maruti Suzuki Swift Dzire ZDi',\n",
       "       'Maruti Suzuki Eeco 5 STR WITH AC HTR', 'Maruti Suzuki Dzire',\n",
       "       'Honda City VX Petrol', 'Fiat Petra ELX 1.2 PS',\n",
       "       'Mahindra Scorpio', 'Jaguar XE XE Portfolio', 'Honda Brio VX AT',\n",
       "       'Ford EcoSport Trend 1.5L TDCi', 'Maruti Suzuki Dzire VDI',\n",
       "       'Honda City 1.5 EXi New', 'Hyundai Verna 1.6 CRDI SX',\n",
       "       'Hyundai Grand i10 Asta 1.2 Kappa VTVT',\n",
       "       'Maruti Suzuki Celerio VDi', 'Toyota Corolla Altis 1.8 J',\n",
       "       'Maruti Suzuki SX4', 'Honda City ZX VTEC',\n",
       "       'Maruti Suzuki SX4 ZXI MT', 'Toyota Innova 2.0 G4',\n",
       "       'Hyundai Eon Sportz', 'Maruti Suzuki Ertiga VDi',\n",
       "       'Hyundai Verna Fluidic New', 'Hyundai Creta 1.6 SX Plus Petrol',\n",
       "       'Honda Amaze 1.5 SX i DTEC',\n",
       "       'Volkswagen Vento Konekt Diesel Highline', 'Hyundai Elantra 1.8 S',\n",
       "       'Audi A8', 'Mahindra Xylo D2 BS IV', 'Mahindra Scorpio Vlx BSIV',\n",
       "       'Mercedes Benz B Class B180 Sports', 'Mahindra Thar CRDe 4x4 AC',\n",
       "       'Honda City', 'Renault Duster 110PS Diesel RxZ',\n",
       "       'Hyundai i20 Magna O 1.2', 'Maruti Suzuki Ertiga',\n",
       "       'Maruti Suzuki Baleno Sigma 1.2', 'Mahindra KUV100 K8 D 6 STR',\n",
       "       'Hyundai Elite i20', 'Ford Ikon 1.3 Flair Josh 100',\n",
       "       'Toyota Corolla Altis Diesel D4DG',\n",
       "       'Maruti Suzuki Swift Dzire VXi 1.2 BS IV',\n",
       "       'Volkswagen Polo Highline1.2L P', 'Commercial Car Ta',\n",
       "       'Tata Nano GenX XMA', 'Maruti Suzuki Wagon R LXI BS IV',\n",
       "       'Audi A3 Cabriolet 40 TFSI', 'Maruti Suzuki Swift Dzire Tour VDi',\n",
       "       'Toyota Fortuner 3.0 4x2 MT', 'Tata Zest XE 75 PS Diesel',\n",
       "       'Ford Fiesta', 'Tata Sumo Gold LX BS IV',\n",
       "       'Hyundai Fluidic Verna 1.6 CRDi SX',\n",
       "       '7 SEATER MAHINDRA BOLERO IN VERY GOOD',\n",
       "       'Mahindra Scorpio 2.6 CRDe', 'Maruti Suzuki Alto LXi BS III',\n",
       "       'Renault Duster 85PS Diesel RxL Optional with Nav',\n",
       "       'Maruti Suzuki Omni', 'Mini Cooper S', 'Honda City SV',\n",
       "       'Volkswagen Vento Highline Plus 1.5 Diesel',\n",
       "       'Ford Figo Diesel EXI', 'Honda Amaze 1.5 S i DTEC', 'tata',\n",
       "       'Chevrolet Beat LS Diesel', 'Maruti Suzuki Wagon R 1.0 VXi',\n",
       "       'Maruti Suzuki Swift', 'Datsun Redi GO S',\n",
       "       'Tata Indigo eCS LX CR4 BS IV', 'Hindustan Motors Ambassador',\n",
       "       'very good condition tata bolts are av',\n",
       "       'Hyundai i10 Magna 1.2 Kappa2', 'Mahindra Scorpio S10 4WD',\n",
       "       'Audi A4 2.0 TDI 177bhp Premium', 'Chevrolet Tavera Neo',\n",
       "       'Maruti Suzuki Baleno Delta 1.2',\n",
       "       'Maruti Suzuki Wagon R LXi BS III', 'Maruti Suzuki Ertiga LDi',\n",
       "       'Tata Bolt XM Petrol', 'Maruti Suzuki Zen LX BSII',\n",
       "       'Tata Indica eV2 LS', 'Mahindra Scorpio S10',\n",
       "       'Mahindra Scorpio VLX Special Edition BS III',\n",
       "       'Mahindra TUV300 T4 Plus', 'Mahindra Bolero Power Plus SLE',\n",
       "       'Mini Cooper S 1.6', 'Maruti Suzuki Wagon R VXi BS III',\n",
       "       'Audi Q3 2.0 TDI quattro Premium', 'Hyundai Santro Xing GLS',\n",
       "       'Hyundai Xcent Base 1.1 CRDi',\n",
       "       'Maruti Suzuki Swift Dzire Tour VXi',\n",
       "       'Maruti Suzuki Swift Dzire Tour LXi', 'Hyundai Accent GLX',\n",
       "       'Maruti Suzuki Maruti 800 Std', 'Maruti Suzuki Swift Dzire car',\n",
       "       'Mahindra Quanto C8', 'Maruti Suzuki Swift LDi',\n",
       "       'Maruti Suzuki Ertiga ZXi',\n",
       "       'Ford Figo Duratorq Diesel Titanium 1.4',\n",
       "       'Hyundai Santro Xing XL AT eRLX Euro III',\n",
       "       'Volkswagen Jetta Comfortline 1.9 TDI AT',\n",
       "       'Maruti Suzuki A Star Lxi', 'Chevrolet Beat LS Petrol',\n",
       "       'Toyota Innova 2.0 G 8 STR BS IV', 'Toyota Innova 2.0 V',\n",
       "       'Renault Duster RxL Petrol', 'Chevrolet Cruze LTZ AT',\n",
       "       'Hyundai Verna 1.6 EX VTVT', 'Honda Amaze 1.5 E i DTEC', 'Audi Q7',\n",
       "       'Hyundai Eon Era Plus', 'Hyundai i10 Era',\n",
       "       'Swift Dzire Tour 27 Dec 2016 Regis', 'Mahindra XUV500',\n",
       "       'Volkswagen Passat Diesel Comfortline AT',\n",
       "       'Maruti Suzuki Swift Dzire Tour LDi', 'Mahindra Quanto C4',\n",
       "       'Hyundai Accent GLE', 'Skoda Fabia 1.2L Diesel Elegance',\n",
       "       'Tata Indigo CS eLX BS IV', 'Hyundai Xcent SX 1.2',\n",
       "       'Toyota Etios Liva', 'Maruti Suzuki Wagon R VXI BS IV',\n",
       "       'Maruti Suzuki Wagon R Duo Lxi',\n",
       "       'Audi Q5 2.0 TDI quattro Premium Plus',\n",
       "       'Maruti Suzuki Vitara Brezza', 'Ford EcoSport', 'tata Indica',\n",
       "       'urgent sell my Mahindra qu',\n",
       "       'Hyundai Santro Xing XL eRLX Euro III', 'Maruti Suzuki Alto 800',\n",
       "       'Hyundai Getz Prime 1.3 GVS', 'BMW 7 Series 740Li Sedan',\n",
       "       'Volkswagen Polo', 'Hyundai Santro Xing XO eRLX Euro III',\n",
       "       'Tata Zest Quadrajet 1.3', 'Hyundai Grand i10 Asta 1.1 CRDi',\n",
       "       'Hyundai Creta', 'Toyota Innova 2.5 E 8 STR', 'Ford Ikon 1.6 Nxt',\n",
       "       'Mahindra Scorpio S4', 'Tata Indigo LX TDI BS III',\n",
       "       'I want to sell my commercial car due t', 'Tata ZEST 6 month old',\n",
       "       'Maruti Suzuki Alto 800 Vxi', 'Chevrolet Beat LT Opt Diesel',\n",
       "       'Ford Figo Petrol LXI', 'Maruti Suzuki Swift Dzire VDi',\n",
       "       'Maruti Suzuki Swift VXi 1.2 BS IV',\n",
       "       'Mahindra Scorpio VLX 2WD BS IV', 'urgent sale Ta',\n",
       "       'Hyundai i10 Sportz 1.2', 'Honda City 1.5 S Inspire',\n",
       "       'Maruti Suzuki Ritz', 'Maruti Suzuki Alto 800 LXI CNG O',\n",
       "       'Hyundai Verna 1.6 CRDI SX Plus AT', 'Toyota Qualis',\n",
       "       'selling car Ta', 'all paper updated tata indica v2 and u',\n",
       "       'Tata Indica V2 Xeta e GLE', 'Maruti Suzuki Esteem LXi BS III',\n",
       "       'Mahindra Scorpio SLE BS IV', 'Honda Brio',\n",
       "       'Tata Indica V2 DLS BS III', 'Mahindra Bolero SLE BS IV',\n",
       "       'Mahindra Scorpio VLX 2.2 mHawk Airbag BSIV',\n",
       "       'Chevrolet Enjoy 1.4 LS 8 STR', 'Chevrolet Enjoy',\n",
       "       'Maruti Suzuki Swift VDi ABS',\n",
       "       'Hyundai Grand i10 Sportz 1.2 Kappa VTVT',\n",
       "       'Renault Duster 85 PS RxL Diesel', 'Honda Mobilio', 'Toyota Etios',\n",
       "       'Volkswagen Vento Comfortline Petrol', 'Maruti Suzuki Dzire ZXI',\n",
       "       'Honda Amaze 1.2 VX i VTEC', 'Maruti Suzuki Alto', 'Hyundai Getz',\n",
       "       'Maruti Ertiga showroom condition with',\n",
       "       'Maruti Suzuki Omni 8 STR BS III', 'Maruti Suzuki Maruti 800 AC',\n",
       "       'Commercial Chevrolet Sail Hatchback ca', 'Honda Accord',\n",
       "       'Maruti Suzuki Alto 800 Lx', 'Tata Indigo CS',\n",
       "       'Mahindra Jeep MM 550 XDB', 'Maruti Suzuki S Cross Sigma 1.3',\n",
       "       'Hyundai Verna Fluidic',\n",
       "       'Mercedes Benz A Class A 180 Sport Petrol', 'Hyundai i20 Active',\n",
       "       'Hyundai Santro', 'Honda City ZX EXi',\n",
       "       'Maruti Suzuki Omni LPG BS IV', 'Maruti Suzuki Wagon R VXi Minor',\n",
       "       'Maruti Suzuki Ritz VXI', 'Hyundai Eon Magna',\n",
       "       'Hyundai i10 Magna 1.2', 'Renault Duster',\n",
       "       'Hyundai Eon Magna Plus', 'Skoda Fabia',\n",
       "       'Maruti Suzuki Wagon R AX BSIV', 'Hyundai Elite i20 Magna 1.2',\n",
       "       'Tata zest x', 'Sale Hyundai xcent commerc',\n",
       "       'Tata Manza Aura Quadrajet',\n",
       "       'Volkswagen Vento Highline Plus 1.5 Diesel AT',\n",
       "       'Maruti Suzuki Ritz VXI ABS', 'BMW X1 xDrive20d xLine',\n",
       "       'Chevrolet Beat Diesel', 'Maruti Suzuki Versa DX2 8 SEATER BSIII',\n",
       "       'Fiat Linea Emotion 1.4 L T Jet Petrol',\n",
       "       'Tata indigo 2017 top model..', 'Chevrolet Spark LT 1.0 Airbag',\n",
       "       'Mahindra Scorpio SLX', 'Nissan Sunny',\n",
       "       'Toyota Innova 2.0 G1 Petrol 8seater', 'Maruti Suzuki Swift GLAM',\n",
       "       'Maruti Suzuki Vitara Brezza ZDi', 'Toyota Fortuner 3.0 4x4 MT',\n",
       "       'Chevrolet Beat', 'Chevrolet Cruze LTZ',\n",
       "       'Maruti Suzuki Swift Dzire good car fo', 'Tata Indica V2',\n",
       "       'Commercial , DZire LDI, 2016, for sale',\n",
       "       'Maruti Suzuki Ertiga Vxi', 'Toyota Corolla Altis VL AT Petrol',\n",
       "       'Tata Tiago Revotron XM', 'Hyundai Xcent S 1.2',\n",
       "       'Mahindra XUV500 W8', 'Toyota Etios Liva GD', 'Mahindra Xylo E8',\n",
       "       'Renault Kwid RXT', 'Audi A4 1.8 TFSI Multitronic Premium Plus',\n",
       "       'Mercedes Benz C Class 200 K MT', 'Ford EcoSport Trend 1.5 Ti VCT',\n",
       "       'Maruti Suzuki SX4 Celebration Diesel',\n",
       "       'Any type car avaiabel hare...comercica',\n",
       "       'Toyota Innova 2.5 G BS III 8 STR',\n",
       "       'Skoda Octavia Classic 1.9 TDI MT', 'Ford Figo Petrol Titanium',\n",
       "       'sell my car Maruti Suzuki Swif', 'Maruti Suzuki Alto K10 VXi',\n",
       "       'Toyota Corolla Altis GL Petrol', 'Chevrolet Beat LT Diesel',\n",
       "       'Tata Indigo CS LS DiCOR', 'Hyundai Getz Prime 1.3 GLX',\n",
       "       'Hyundai Santro Xing GL', 'Maruti Suzuki Alto LX',\n",
       "       'Maruti Suzuki Esteem VXi BS III',\n",
       "       'Renault Duster 85 PS RxL Explore LE',\n",
       "       'Mahindra Scorpio SLX 2.6 Turbo 8 Str', 'Mahindra Logan',\n",
       "       'Mercedes Benz C Class C 220 CDI Avantgarde', 'Hyundai Elantra SX',\n",
       "       'Renault Kwid 1.0 RXT AMT', 'Maruti Suzuki Swift ZXi 1.2 BS IV',\n",
       "       'Hyundai i20 Sportz 1.4 CRDI', 'Hyundai i10',\n",
       "       'Maruti Suzuki Alto K10 New', 'Nissan X Trail Select Variant',\n",
       "       'Tata Sumo Gold Select Variant', 'scratch less Tata I',\n",
       "       'Maruti Suzuki Swift VXI BSIII', 'Hyundai Eon D Lite Plus',\n",
       "       'Maruti Suzuki Alto K10 LXi CNG',\n",
       "       'Volkswagen Polo Highline Exquisite P', 'Tata indigo',\n",
       "       'Toyota Innova 2.5 Z Diesel 7 Seater', 'Chevrolet Spark LT 1.0',\n",
       "       'Mahindra xyl', 'Hyundai Grand i10 Asta 1.2 Kappa VTVT O',\n",
       "       'Toyota Etios Liva G', 'Hyundai i20 Asta 1.4 CRDI 6 Speed',\n",
       "       'Honda City 1.5 S MT', 'Honda City VX O MT Diesel',\n",
       "       'Hyundai i20 Magna 1.2',\n",
       "       'Hyundai Grand i10 Sportz O 1.2 Kappa VTVT', 'Nissan Micra XV',\n",
       "       'Hyundai Elite i20 Sportz 1.2', 'Fiat Punto Emotion 1.2',\n",
       "       'Honda Amaze 1.2 S i VTEC', 'Maruti Suzuki Zen LXi BS III',\n",
       "       'Mahindra Bolero DI BSII', 'Hyunda', 'Renault Kwid 1.0',\n",
       "       'Tata Zest 90', 'Maruti Suzuki Swift VDi',\n",
       "       'I want to sell my car Tata Zest', 'Toyota Etios Liva Diesel',\n",
       "       'Maruti Suzuki Alto AX', 'Honda Jazz S MT', 'Chevrolet Spark',\n",
       "       'Skoda Yeti Ambition 2.0 TDI CR 4x2',\n",
       "       'Renault Duster 110 PS RxZ Diesel Plus',\n",
       "       'Tata Indigo eCS LS CR4 BS IV',\n",
       "       'Commercial Chevrolet beat for sale in',\n",
       "       'Mercedes Benz GLA Class 200 CDI Sport', 'Nissan Sunny XL',\n",
       "       'Mercedes Benz C Class 200 CDI Classic', 'Skoda Laura',\n",
       "       'Land Rover Freelander 2 SE', 'Maruti Suzuki Zen VX',\n",
       "       'Hyundai Sonata Transform 2.4 GDi MT', 'Hyundai Getz GLE',\n",
       "       'Honda City 1.5 V AT', 'Renault Lodgy 85 PS RXL',\n",
       "       'Chevrolet Spark LS 1.0', 'Skoda Fabia 1.2L Diesel Ambiente',\n",
       "       'Maruti Suzuki Wagon R LX BS III', 'Tata Indigo eCS VX CR4 BS IV',\n",
       "       'Renault Kwid RXT Opt', 'Mahindra XUV500 W6', 'BMW X1',\n",
       "       'Maruti Suzuki Swift RS VDI', 'Maruti Suzuki Alto K10 VXi AMT',\n",
       "       'Maruti Suzuki Stingray VXi', 'Honda WR V S MT Petrol',\n",
       "       'Skoda Fabia Classic 1.2 MPI', 'Honda City 1.5 V MT Exclusive',\n",
       "       'Tata Sumo Gold EX BS IV', 'Honda Jazz VX MT', 'Toyota Etios GD',\n",
       "       'Tata Manza Aqua Quadrajet', 'Renault Scala RxL Diesel Travelogue',\n",
       "       'Datsun Go Plus T O', 'Mahindra Scorpio LX BS III', 'Ford Figo',\n",
       "       'Tata Indica', 'Mahindra Scorpio 2.6 SLX', 'Honda City 1.5 E MT',\n",
       "       'Hyundai Verna 1.4 VTVT', 'Ford Figo Diesel EXI Option',\n",
       "       'Volkswagen Vento Comfortline Diesel',\n",
       "       'Ford Endeavor 4x4 Thunder Plus', 'Renault Kwid', 'Tata',\n",
       "       'Tata Vista Quadrajet VX', 'Toyota Innova 2.5 GX BS IV 7 STR',\n",
       "       'Chevrolet Beat PS Diesel', 'Renault Duster 110 PS RxZ Diesel',\n",
       "       'Maruti Suzuki Ciaz ZXi Plus RS',\n",
       "       'Volkswagen Polo Trendline 1.5L D', 'Mahindra XUV500 W8 AWD 2013',\n",
       "       'Tata Zest XM Diesel', 'Mahindra Xylo E8 BS IV',\n",
       "       'Chevrolet Spark 1.0 LT', 'Hyundai Verna 1.6 CRDI E',\n",
       "       'Maruti Suzuki Omni E 8 STR BS IV', 'Toyota Etios G',\n",
       "       'Datsun GO T O', 'Mahindra Scorpio VLX Airbag',\n",
       "       'Chevrolet Sail UVA Petrol LT ABS', 'Well mentained Tata Sumo',\n",
       "       'Force Motors Force One LX ABS 7 STR', 'Maruti Suzuki 800',\n",
       "       'Jaguar XF 2.2 Diesel Luxury', 'Tata Nano Cx BSIV',\n",
       "       'Force Motors One SUV', 'Ford EcoSport Trend 1.5L Ti VCT', 'Yama',\n",
       "       'Chevrolet Sail 1.2 LS', 'Tata Indigo LS',\n",
       "       'Tata Tiago Revotron XZ', 'MARUTI SUZUKI ERTIGA F',\n",
       "       'Mahindra XUV500 W10', 'Tata Sumo Gold FX BSIII',\n",
       "       'Datsun Redi GO T O', 'Maruti Suzuki Alto vxi t',\n",
       "       'Commercial Maruti Suzuki Alto Lxi 800',\n",
       "       'i want sale my car.no emi....uber atta', 'Tata Aria Pleasure 4X2',\n",
       "       'Skoda Rapid Elegance 1.6 TDI CR MT', 'Audi A6 2.0 TDI Premium',\n",
       "       'Hyundai Grand i10 Magna AT 1.2 Kappa VTVT',\n",
       "       'Maruti Suzuki Ritz VDi', 'Volvo S80 Summum D4',\n",
       "       'Hyundai Verna VGT CRDi SX ABS', 'Maruti Suzuki Ritz GENUS VXI',\n",
       "       '2012 Tata Sumo Gold f', 'Honda City ZX GXi',\n",
       "       'Ford Ikon 1.3 CLXi NXt Finesse',\n",
       "       'Mahindra Scorpio W Turbo 2.6DX 9 Seater',\n",
       "       'Maruti Suzuki Swift Dzire',\n",
       "       'Chevrolet Tavera LS B3 10 Seats BSII', 'URJE',\n",
       "       'Tata Nano Lx BSIV', 'tata zest 2017 f', 'Mahindra Xylo D2',\n",
       "       'Used Commercial Maruti Omn', 'Maruti Suzuki 800 Std BS III',\n",
       "       'Tata Indica V2 DLX BS III', 'Renault Duster 110 PS RxL Diesel',\n",
       "       'Maruti Suzuki Estilo LX BS IV', 'Maruti Suzuki Wagon R 1.0',\n",
       "       'Tata Tigor Revotron XZ', 'Tata Indica V2 LS',\n",
       "       'Tata Venture EX 8 STR', 'Volkswagen Polo Comfortline 1.2L P',\n",
       "       'Hyundai Santro Xing XS', 'Tata Nexon', 'Honda Amaze 1.2 E i VTEC',\n",
       "       'Toyota Corolla H2', 'Tata Indigo eCS',\n",
       "       'Maruti Suzuki Omni Limited Edition',\n",
       "       'Hyundai Elite i20 Asta 1.4 CRDI', 'Hyundai Verna'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d358776",
   "metadata": {},
   "source": [
    "df_train['name'].unique() >> helps us to give the unique values present in the ['name'] attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8dac76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b416ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015    91\n",
       "2013    75\n",
       "2014    74\n",
       "2016    61\n",
       "2012    56\n",
       "2011    48\n",
       "2017    48\n",
       "2009    47\n",
       "2010    34\n",
       "2018    26\n",
       "2006    18\n",
       "2019    16\n",
       "2008    15\n",
       "2007    14\n",
       "2003    12\n",
       "2005    10\n",
       "2004    10\n",
       "2000     6\n",
       "2002     4\n",
       "2001     4\n",
       "o...     3\n",
       "sale     3\n",
       "...      3\n",
       "car      2\n",
       "Zest     2\n",
       "digo     1\n",
       "go .     1\n",
       "2 bs     1\n",
       "cent     1\n",
       "SELL     1\n",
       "/-Rs     1\n",
       "k...     1\n",
       "SALE     1\n",
       "r 15     1\n",
       "sell     1\n",
       "d Ex     1\n",
       "d...     1\n",
       "cab      1\n",
       "zire     1\n",
       "EV2      1\n",
       "tion     1\n",
       "r...     1\n",
       "emi      1\n",
       "no.      1\n",
       "odel     1\n",
       "e...     1\n",
       "n...     1\n",
       "Sumo     1\n",
       "o c4     1\n",
       "able     1\n",
       "t xe     1\n",
       "D...     1\n",
       ", Ac     1\n",
       "zest     1\n",
       "ture     1\n",
       "arry     1\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d67b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EV2', '2017', '2015', '2016', 'ture', '2009', '2011', '2013',\n",
       "       '2003', '2014', '2012', '2006', 'zest', '2008', '2010', '2018',\n",
       "       ', Ac', '2005', 'Zest', 'D...', '2007', '2000', 't xe', '2002',\n",
       "       'able', '2004', '2019', 'sale', 'tion', 'o c4', 'o...', 'car',\n",
       "       'Sumo', 'n...', 'e...', '2001', 'odel', 'no.', 'emi', '...',\n",
       "       'r...', 'zire', 'go .', '2 bs', 'cent', '/-Rs', 'k...', 'digo',\n",
       "       'd Ex', 'r 15', 'SALE', 'cab', 'd...', 'sell', 'SELL', 'arry'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbe759b4",
   "metadata": {},
   "source": [
    "Its seems like possitive correlationship between year and Price. As the Year of Purchase is become latest then price of the car increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc00b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f99ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ask For Price    31\n",
       "2,50,000         15\n",
       "3,50,000         12\n",
       "4,50,000         11\n",
       "3,00,000         10\n",
       "                 ..\n",
       "5,44,999          1\n",
       "7,25,000          1\n",
       "23,90,000         1\n",
       "2,39,999          1\n",
       "71,000            1\n",
       "Name: Price, Length: 242, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee84dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1,10,000', '1,80,000', '14,75,000', '6,35,000', '1,00,000',\n",
       "       '2,50,000', '4,99,999', '2,40,000', '60,000', '1,59,000',\n",
       "       '1,20,000', '3,65,000', '2,44,999', '1,60,000', 'Ask For Price',\n",
       "       '4,88,000', '5,35,000', '99,999', '4,25,000', '3,00,000',\n",
       "       '5,00,000', '2,80,000', '3,10,000', '2,70,000', '3,20,000',\n",
       "       '1,75,000', '2,85,000', '5,49,000', '3,80,000', '2,20,000',\n",
       "       '2,89,999', '10,00,000', '90,000', '5,99,000', '8,30,000',\n",
       "       '2,84,999', '2,00,000', '4,89,999', '3,85,000', '2,51,111',\n",
       "       '4,50,000', '8,60,000', '75,000', '9,44,999', '28,00,000',\n",
       "       '1,35,000', '4,00,000', '8,55,000', '3,49,999', '2,65,000',\n",
       "       '2,49,999', '6,00,000', '1,78,000', '4,80,000', '4,30,000',\n",
       "       '9,50,000', '3,45,000', '2,45,000', '3,90,000', '6,90,000',\n",
       "       '14,00,000', '7,30,000', '5,84,999', '5,01,000', '95,000',\n",
       "       '3,44,999', '5,99,999', '3,51,000', '3,40,000', '3,71,500',\n",
       "       '32,000', '31,00,000', '15,25,000', '2,90,000', '2,74,999',\n",
       "       '2,75,000', '5,40,000', '1,55,000', '4,01,919', '35,999',\n",
       "       '18,91,111', '4,75,000', '1,95,000', '2,99,000', '1,45,000',\n",
       "       '3,95,000', '3,24,999', '3,25,000', '5,25,000', '2,35,000',\n",
       "       '15,10,000', '3,75,000', '4,98,000', '90,001', '70,000',\n",
       "       '7,99,999', '2,30,000', '3,89,700', '6,99,000', '1,05,000',\n",
       "       '14,99,000', '6,50,000', '2,25,000', '1,25,000', '6,10,000',\n",
       "       '3,15,000', '80,000', '57,000', '2,60,000', '5,69,999', '9,00,000',\n",
       "       '1,40,000', '1,89,500', '5,24,999', '5,50,000', '99,000',\n",
       "       '9,84,999', '8,00,000', '1,90,000', '3,70,000', '2,99,999',\n",
       "       '6,49,999', '3,79,000', '2,78,000', '3,50,000', '2,39,999',\n",
       "       '1,30,000', '23,90,000', '7,25,000', '5,44,999', '88,000',\n",
       "       '2,19,000', '16,00,000', '15,40,000', '7,50,000', '1,50,000',\n",
       "       '4,85,000', '4,99,000', '3,72,000', '1,15,000', '5,10,000',\n",
       "       '2,10,000', '69,999', '5,70,000', '2,24,999', '4,95,000',\n",
       "       '3,30,000', '4,90,000', '65,000', '1,62,000', '59,000', '50,500',\n",
       "       '3,99,999', '1,99,999', '2,55,000', '3,81,000', '85,000', '40,000',\n",
       "       '4,48,999', '6,15,000', '4,44,999', '15,00,000', '8,65,000',\n",
       "       '5,74,999', '1,49,000', '4,19,000', '11,50,000', '1,70,000',\n",
       "       '9,40,000', '39,999', '5,75,000', '7,90,000', '2,15,000',\n",
       "       '5,00,001', '5,80,000', '9,70,000', '2,95,000', '1,14,990',\n",
       "       '1,85,000', '45,000', '98,500', '72,500', '7,15,000', '12,25,000',\n",
       "       '3,60,000', '12,00,000', '19,00,000', '6,89,999', '4,10,000',\n",
       "       '3,29,500', '3,55,000', '5,19,000', '5,60,000', '6,44,999',\n",
       "       '1,79,000', '1,79,999', '1,74,999', '1,69,500', '3,11,000',\n",
       "       '1,69,999', '1,58,400', '4,48,000', '4,24,999', '1,88,000',\n",
       "       '20,00,000', '3,99,000', '3,74,999', '21,00,000', '55,000',\n",
       "       '14,90,000', '2,69,000', '1,59,500', '53,000', '85,00,003',\n",
       "       '4,74,999', '1,68,000', '1,82,000', '68,000', '4,15,000',\n",
       "       '4,24,000', '1,65,000', '29,00,000', '7,60,000', '8,49,999',\n",
       "       '4,35,000', '8,95,000', '7,01,000', '21,90,000', '1,99,000',\n",
       "       '4,65,000', '10,65,000', '5,49,999', '4,49,999', '15,99,000',\n",
       "       '48,000', '18,50,000', '2,05,000', '42,000', '52,000', '30,000',\n",
       "       '49,000', '71,000'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86696da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f5d5c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45,000 kms      24\n",
       "50,000 kms      20\n",
       "20,000 kms      19\n",
       "35,000 kms      18\n",
       "60,000 kms      18\n",
       "                ..\n",
       "1,29,000 kms     1\n",
       "30,600 kms       1\n",
       "77,000 kms       1\n",
       "30,201 kms       1\n",
       "24,800 kms       1\n",
       "Name: kms_driven, Length: 231, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['kms_driven'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d071930d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '23,452 kms', '47,000 kms', '29,000 kms', '56,400 kms',\n",
       "       '60,000 kms', '42,000 kms', '6,800 kms', '27,000 kms',\n",
       "       '50,000 kms', '23,000 kms', '15,487 kms', '55,000 kms',\n",
       "       '70,000 kms', '22,000 kms', '40,000 kms', '16,000 kms',\n",
       "       '80,000 kms', '37,000 kms', '53,000 kms', '40 kms', '1,32,000 kms',\n",
       "       '18,000 kms', '6,200 kms', '1,75,430 kms', '58,000 kms',\n",
       "       '65,000 kms', '39,000 kms', '30,874 kms', '4,500 kms',\n",
       "       '20,000 kms', '30,000 kms', '24,530 kms', '46,000 kms',\n",
       "       '28,000 kms', '59,000 kms', '10,750 kms', '35,522 kms',\n",
       "       '2,500 kms', '95,000 kms', '45,000 kms', '8,500 kms', '11,000 kms',\n",
       "       '1,04,000 kms', '68,000 kms', '59,910 kms', '36,000 kms',\n",
       "       '51,000 kms', '73,000 kms', '25,000 kms', '4,000 kms',\n",
       "       '48,000 kms', '75,000 kms', '31,000 kms', '35,000 kms',\n",
       "       '1,95,000 kms', '588 kms', '7,500 kms', '38,000 kms', '41,000 kms',\n",
       "       '44,005 kms', '18,500 kms', '12,516 kms', '1,20,000 kms',\n",
       "       '1,16,000 kms', '1,70,000 kms', '32,000 kms', '57,923 kms',\n",
       "       '13,000 kms', '34,000 kms', '38,900 kms', '1,02,563 kms',\n",
       "       '33,000 kms', '48,508 kms', '7,000 kms', '15,000 kms',\n",
       "       '1,00,000 kms', '9,000 kms', '84,000 kms', '39,522 kms',\n",
       "       '1,60,000 kms', '1,800 kms', '41,800 kms', '1,80,000 kms',\n",
       "       '65 kms', '73 kms', '44,000 kms', '56,000 kms', '56,758 kms',\n",
       "       '90,000 kms', '97,200 kms', '60,105 kms', '99,000 kms',\n",
       "       '54,500 kms', '12,500 kms', '32,700 kms', '82,000 kms',\n",
       "       '48,006 kms', '15,574 kms', '22,134 kms', '12,000 kms',\n",
       "       '1,75,400 kms', '16,934 kms', '39,700 kms', '0,000 kms',\n",
       "       '97,000 kms', '1,66,000 kms', '63,000 kms', '45,863 kms',\n",
       "       '85,000 kms', '43,000 kms', '37,458 kms', '43,200 kms',\n",
       "       '5,000 kms', '54,870 kms', '43,222 kms', '49,000 kms',\n",
       "       '13,349 kms', '55,800 kms', '10,000 kms', '2,100 kms',\n",
       "       '19,000 kms', '1,29,000 kms', '30,600 kms', '80,200 kms',\n",
       "       '77,000 kms', '30,201 kms', '56,450 kms', '74,000 kms',\n",
       "       '91,200 kms', '45,933 kms', '9,300 kms', '6,000 kms', '58,559 kms',\n",
       "       '72,000 kms', '11,400 kms', '122 kms', '64,000 kms', '54,000 kms',\n",
       "       '21,000 kms', '14,000 kms', '26,000 kms', '1,600 kms', '7,400 kms',\n",
       "       '24,000 kms', '9,800 kms', '35,550 kms', '3,000 kms', '1,500 kms',\n",
       "       '15,975 kms', '1,31,000 kms', '3,500 kms', '28,600 kms',\n",
       "       '1,000 kms', '85,960 kms', '52,000 kms', '00 kms', '1,37,495 kms',\n",
       "       '76,000 kms', '55,700 kms', '9,400 kms', '300 kms', '62,000 kms',\n",
       "       '2,110 kms', '36,200 kms', '8,000 kms', '49,500 kms', '19,336 kms',\n",
       "       '87,000 kms', '37,200 kms', '69,900 kms', '59,466 kms',\n",
       "       '2,137 kms', '1,625 kms', '24,695 kms', '33,600 kms',\n",
       "       '1,30,000 kms', '7,800 kms', '2,00,000 kms', '36,469 kms',\n",
       "       '28,400 kms', '42,590 kms', '15,141 kms', '34,580 kms',\n",
       "       '38,200 kms', '69,000 kms', '65,480 kms', '24,652 kms',\n",
       "       '45,872 kms', '24,330 kms', '5,600 kms', '4,00,000 kms',\n",
       "       '10,544 kms', '383 kms', '5 kms', '95,500 kms', '1,00,200 kms',\n",
       "       '67,000 kms', '65,422 kms', '3,600 kms', '29,500 kms',\n",
       "       '52,500 kms', '90,001 kms', '66,000 kms', '38,500 kms',\n",
       "       '3,200 kms', '60 kms', '2,550 kms', '81,876 kms', '2,200 kms',\n",
       "       '1,40,000 kms', '1,50,000 kms', '33,333 kms', '28,028 kms',\n",
       "       '11,500 kms', '1,33,000 kms', '72,160 kms', '47,900 kms',\n",
       "       '13,500 kms', '1,46,000 kms', '68,485 kms', '1,03,553 kms',\n",
       "       '33,400 kms', '38,600 kms', '57,000 kms', '100 kms', '2,800 kms',\n",
       "       '1,00,800 kms', '0 kms', 'Petrol', '1,17,000 kms', '24,800 kms'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['kms_driven'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50012a6e",
   "metadata": {},
   "source": [
    "As we see, if the car is less driven in terms of kilometer range, then price of the car is more.\n",
    "'kms_drive' and 'Car Price' both are inversly proportional to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773da72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5748967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Petrol    344\n",
       "Diesel    320\n",
       "LPG         1\n",
       "Name: fuel_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['fuel_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea31e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Diesel', 'Petrol', 'LPG'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['fuel_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9c889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87c017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8181e17d",
   "metadata": {},
   "source": [
    "Below is the data insights and obesrvation on the training data that I need to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288f30c",
   "metadata": {},
   "source": [
    "**Quality Summary >>**\n",
    "    \n",
    "    Name, Company year, Price, >> has non-null values >> data type is Object\n",
    "    kms_driven, fuel_type      >> has some null values >> data type is Object\n",
    "    \n",
    "**1) name >>**\n",
    "\n",
    "    a) Name Attribute values are inconsistent (mix of Categorical &  Numerical)\n",
    "    b) We will select only first 3 words of the name    \n",
    "\n",
    "**2) Year >>**\n",
    "\n",
    "    a) Year attribute has lots of Non Year Values/ garbage values\n",
    "    b) We need to convert 'Object' data type into 'Integer' data type.\n",
    "\n",
    "**3) Price >>**\n",
    "\n",
    "    a) We need to remove 'Ask For Price' from the price attributes.\n",
    "    b) We need to remove commas from this.   \n",
    "    c) We need to convert 'Object' data type into 'Integer' data type.\n",
    "    \n",
    "**4) kms_driven >>**\n",
    "    \n",
    "    a) We need to convert 'Object' data type into 'Integer' data type. \n",
    "    b) We need to remove commas from this.\n",
    "    c) We need to remove 'kms' from the integer values. e.g. '2,875 kms'\n",
    "    \n",
    "**5) fuel_type >>**\n",
    "\n",
    "    a) We need to take care of NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794ce3f",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4256b3",
   "metadata": {},
   "source": [
    "As we know that, Machine Learning Model doesn't understand the Raw data, Hence we are doing the pre-processing on the data to feed the data to ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56198fbe",
   "metadata": {},
   "source": [
    "**1) name >>**\n",
    "\n",
    "    a) Name Attribute values are inconsistent (mix of Categorical &  Numerical)\n",
    "    b) We will select only first 3 words of the name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7100972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812                                  TATA INDI\n",
       "29                          Mahindra Bolero DI\n",
       "49     Mitsubishi Pajero Sport Limited Edition\n",
       "105              Maruti Suzuki Ertiga ZXI Plus\n",
       "616                                  Sale tata\n",
       "                        ...                   \n",
       "218        Force Motors Force One LX ABS 7 STR\n",
       "223                               Toyota Etios\n",
       "271            Renault Duster 85 PS RxE Diesel\n",
       "474                Hyundai Xcent Base 1.1 CRDi\n",
       "355                              Hyundai Verna\n",
       "Name: name, Length: 713, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f9833",
   "metadata": {},
   "source": [
    "First I get the access the \"name\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b915de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812                                     [TATA, INDI]\n",
       "29                            [Mahindra, Bolero, DI]\n",
       "49     [Mitsubishi, Pajero, Sport, Limited, Edition]\n",
       "105              [Maruti, Suzuki, Ertiga, ZXI, Plus]\n",
       "616                                     [Sale, tata]\n",
       "                           ...                      \n",
       "218     [Force, Motors, Force, One, LX, ABS, 7, STR]\n",
       "223                                  [Toyota, Etios]\n",
       "271           [Renault, Duster, 85, PS, RxE, Diesel]\n",
       "474                [Hyundai, Xcent, Base, 1.1, CRDi]\n",
       "355                                 [Hyundai, Verna]\n",
       "Name: name, Length: 713, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name'].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51e080",
   "metadata": {},
   "source": [
    "Here, I split the data by space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82690a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812                   [TATA, INDI]\n",
       "29          [Mahindra, Bolero, DI]\n",
       "49     [Mitsubishi, Pajero, Sport]\n",
       "105       [Maruti, Suzuki, Ertiga]\n",
       "616                   [Sale, tata]\n",
       "                  ...             \n",
       "218         [Force, Motors, Force]\n",
       "223                [Toyota, Etios]\n",
       "271          [Renault, Duster, 85]\n",
       "474         [Hyundai, Xcent, Base]\n",
       "355               [Hyundai, Verna]\n",
       "Name: name, Length: 713, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name'].str.split().str.slice(0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048735ef",
   "metadata": {},
   "source": [
    "I perform the slicing operation from 0th Index (Start_index) till 3rd Index(Stop Index) i.e (0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "852b194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812                  TATA INDI\n",
       "29          Mahindra Bolero DI\n",
       "49     Mitsubishi Pajero Sport\n",
       "105       Maruti Suzuki Ertiga\n",
       "616                  Sale tata\n",
       "                ...           \n",
       "218         Force Motors Force\n",
       "223               Toyota Etios\n",
       "271          Renault Duster 85\n",
       "474         Hyundai Xcent Base\n",
       "355              Hyundai Verna\n",
       "Name: name, Length: 713, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name'].str.split().str.slice(0,3).str.join(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abcbdbb",
   "metadata": {},
   "source": [
    "Here, I join sliced data. Here, I select the first three letter of the 'name' attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dd9c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1431/1447433096.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['name']=df_train['name'].str.split().str.slice(0,3).str.join(' ')\n"
     ]
    }
   ],
   "source": [
    "df_train['name']=df_train['name'].str.split().str.slice(0,3).str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f7670cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812                  TATA INDI\n",
       "29          Mahindra Bolero DI\n",
       "49     Mitsubishi Pajero Sport\n",
       "105       Maruti Suzuki Ertiga\n",
       "616                  Sale tata\n",
       "                ...           \n",
       "218         Force Motors Force\n",
       "223               Toyota Etios\n",
       "271          Renault Duster 85\n",
       "474         Hyundai Xcent Base\n",
       "355              Hyundai Verna\n",
       "Name: name, Length: 713, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8704dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1431/1149960725.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['name']=df_test['name'].str.split().str.slice(0,3).str.join(' ')\n"
     ]
    }
   ],
   "source": [
    "df_test['name']=df_test['name'].str.split().str.slice(0,3).str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7346064d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347          Hyundai Grand i10\n",
       "674         Maruti Suzuki Alto\n",
       "791          Chevrolet Beat LS\n",
       "837             Datsun Go Plus\n",
       "56        Mahindra Scorpio S10\n",
       "                ...           \n",
       "694    Mitsubishi Pajero Sport\n",
       "428         Maruti Suzuki Alto\n",
       "431            Tata Manza ELAN\n",
       "563        Mahindra XUV500 W10\n",
       "484         Mahindra XUV500 W6\n",
       "Name: name, Length: 179, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f81235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78d47c62",
   "metadata": {},
   "source": [
    "**2) Year >>**\n",
    "\n",
    "    a) Year attribute has lots of Non Year Values/ garbage values\n",
    "    b) We need to convert 'Object' data type into 'Integer' data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de27c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[df_train['year'].str.isnumeric()]\n",
    "df_test=df_test[df_test['year'].str.isnumeric()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907be87f",
   "metadata": {},
   "source": [
    "Here, I'm selecting the numeric data which is having string datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27b7726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['year']=df_train['year'].astype(int)\n",
    "df_test['year']=df_test['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60712de",
   "metadata": {},
   "source": [
    "Now, I have converted the selected data from object to integer data type using astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad0d7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train size:  (669, 6)\n",
      "df_test size:  (173, 6)\n"
     ]
    }
   ],
   "source": [
    "print('df_train size: ',df_train.shape)\n",
    "print('df_test size: ',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b76f133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017 2015 2016 2009 2011 2013 2003 2014 2012 2006 2008 2010 2018 2005\n",
      " 2007 2000 2002 2004 2019 2001]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['year'].unique())\n",
    "print(df_train['year'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84ac2c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017 2016 2014 2015 2019 2011 2012 2001 2002 2013 2010 2007 2018 2009\n",
      " 1995 2006 2005 2004 2003 2000 2008]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['year'].unique())\n",
    "print(df_train['year'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13caf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03a10320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[df_train['Price'] != 'Ask For Price']\n",
    "df_test=df_test[df_test['Price'] != 'Ask For Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079c3bf",
   "metadata": {},
   "source": [
    "Here, I have selected the data which is not equal to 'Ask For Price', means, i select all the data except 'Ask For Price' this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6e61315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Price']=df_train['Price'].str.replace(',','').astype(int)\n",
    "df_test['Price']=df_test['Price'].str.replace(',','').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06708c59",
   "metadata": {},
   "source": [
    "I deleted the commas from the price and used astype to change the selected data's object data type to an integer data type (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56529a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train size:  (649, 6)\n",
      "df_test size:  (170, 6)\n"
     ]
    }
   ],
   "source": [
    "print('df_train size: ',df_train.shape)\n",
    "print('df_test size: ',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d31d4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 180000 1475000  635000  250000  499999  240000   60000  159000  120000\n",
      "  365000  100000  244999  160000  488000  535000   99999  425000  300000\n",
      "  500000  280000  270000  320000  175000  285000  549000  380000  220000\n",
      "  289999 1000000   90000  599000  830000  284999  200000  489999  385000\n",
      "  251111  450000  860000   75000  944999 2800000  135000  400000  855000\n",
      "  310000  349999  265000  110000  249999  600000  178000  480000  430000\n",
      "  950000  345000  245000  390000  690000 1400000  730000  584999  501000\n",
      "   95000  344999  599999  351000  340000   32000 3100000 1525000  290000\n",
      "  274999  275000  540000  155000  401919   35999 1891111  475000  195000\n",
      "  299000  145000  395000  324999  325000  525000  235000 1510000  375000\n",
      "  498000   90001   70000  799999  230000  389700  699000  105000 1499000\n",
      "  650000  225000  125000  610000  315000   80000   57000  260000  569999\n",
      "  900000  140000  189500  524999  550000   99000  984999  800000  190000\n",
      "  299999  649999  379000  278000  350000  239999  130000 2390000  725000\n",
      "  544999   88000  219000 1600000 1540000  750000  150000  485000  499000\n",
      "  372000  115000  510000  210000   69999  570000  224999  495000  330000\n",
      "  490000   65000  162000   59000   50500  399999  199999  255000  381000\n",
      "   85000   40000  448999  615000  444999 1500000  865000  574999  149000\n",
      "  419000 1150000  940000   39999  575000  790000  370000  215000  500001\n",
      "  580000  970000  295000  114990  185000   45000   98500   72500  715000\n",
      " 1225000  360000 1200000 1900000  689999  410000  329500  355000  519000\n",
      "  560000  644999  179000  179999  174999  169500  311000  169999  158400\n",
      "  448000  424999  188000 2000000  399000  374999 2100000   55000 1490000\n",
      "  269000  159500   53000 8500003  474999  168000  182000   68000  415000\n",
      "  424000  165000 2900000  760000  849999  435000  895000  701000 2190000\n",
      "  199000  465000 1065000  549999  449999 1599000   48000 1850000  205000\n",
      "   42000   52000   30000   49000   71000  170000]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Price'].unique())\n",
    "print(df_train['Price'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "906c7bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 524999  270000  189000  285000  395000  200000  568500  140000  150000\n",
      "  405000  699999  349999  600000  284999  335000  899000   40000  225000\n",
      "  400000  170000  900000  180000  195000 1891111  250000  449999  320000\n",
      "  365000   99999  750000   69999  690000  130000  160000   80000 1299000\n",
      "  565000   85000  425000  749999  235000  549900  299999  610000  265000\n",
      "   35000  550000  650000  501000  360000  290000  950000  700000  125000\n",
      "  230000  375000  350000  560000  110000  430000  175000 1075000   95000\n",
      "  530000  520000  599999  830000  240000 1025000   70000  190000  209000\n",
      "  182000  199000  399000  280000  865000  199999  244999 1130000  105000\n",
      "  415000  189700 1000000  215000  689999  795000  399999  100000  330000\n",
      "  260000   32000  370000  149000   90000 1350000  549999  274999  372000\n",
      "   60000  770000  499999  699000  220000   51999  580000  380000 1200000\n",
      "  310000  165000  115000  135000  401000  590000  390000   30000  675000\n",
      "  185000 1499000  123000 1074999  470000  500000  475000  340000 1725000\n",
      "  155555  548900]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['Price'].unique())\n",
    "print(df_test['Price'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afe1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9493074c",
   "metadata": {},
   "source": [
    "**4) kms_driven >>**\n",
    "    \n",
    "    a) We need to convert 'Object' data type into 'Integer' data type. \n",
    "    b) We need to remove commas from this.\n",
    "    c) We need to remove 'kms' from the integer values. e.g. '2,875 kms'\n",
    "    d) We need to take care of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8964f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['kms_driven']=df_train['kms_driven'].str.split().str.get(0).str.replace(',','')\n",
    "df_train=df_train[df_train['kms_driven'].str.isnumeric()]\n",
    "df_train['kms_driven']=df_train['kms_driven'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b021d85",
   "metadata": {},
   "source": [
    "In this case, I separated the data into the first value and the second value after removing the commas from the kms drive. and by selecting only the first index (0th index), I mean (0). (2875).\n",
    "Additionally, a few of the numbers were NaNs, so I used df train['kms driven'].\n",
    "To pick all numerical values with object datatypes, use the function str.isnumeric().\n",
    "Then, I used astype to transform the chosen data from object to integer data type (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cd4b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['kms_driven']=df_test['kms_driven'].str.split().str.get(0).str.replace(',','')\n",
    "df_test=df_test[df_test['kms_driven'].str.isnumeric()]\n",
    "df_test['kms_driven']=df_test['kms_driven'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "866095f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23452  47000  29000  56400  60000  42000   6800  27000  50000  23000\n",
      "  15487  55000  70000  22000  40000  80000  37000  53000     40 132000\n",
      "  18000   6200 175430  58000  65000  39000  30874   4500  20000  30000\n",
      "  24530  46000  28000  59000  10750  35522   2500  95000  45000   8500\n",
      "  11000  16000 104000  68000  59910  36000  51000  73000  25000   4000\n",
      "  48000  75000  31000  35000 195000    588  38000  41000  44005  18500\n",
      "  12516 120000 116000 170000  32000  57923  13000  34000 102563  33000\n",
      "  48508   7000  15000 100000   9000  39522 160000   1800  41800     65\n",
      "     73  44000  56000  56758  90000  97200  60105  99000  54500  12500\n",
      "  32700  82000  48006  22134  12000 175400  16934  39700      0  97000\n",
      " 166000  63000  45863  85000  43000  37458  43200   5000  54870  43222\n",
      "  49000  13349  55800  10000   2100  19000 129000  30600  80200  77000\n",
      "  30201  56450  74000  91200  45933   9300   6000  58559  72000  11400\n",
      "    122  64000  54000  21000  14000  26000   1600   7400   9800  35550\n",
      "   3000  15975 131000   3500  28600   1000  85960 137495  76000  55700\n",
      "   9400    300  62000   2110  36200  52000   8000  19336  87000  37200\n",
      "  69900  59466   2137   1625  24695  33600 130000   7800 200000  36469\n",
      "  28400  42590  15141  34580  38200  69000  65480  24652  45872  24330\n",
      "   5600 400000  10544    383  95500 100200  67000  65422   3600  29500\n",
      "  52500  90001  66000  38500   3200     60   2550  81876   2200 140000\n",
      " 150000  33333  11500 133000  72160  47900  13500 146000  68485 103553\n",
      "  33400  38600  57000    100   2800   7500 100800 117000  24800   1500]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['kms_driven'].unique())\n",
    "print(df_train['kms_driven'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e930d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6821  38000  31000  13900  35000 130000      0  65000  62000  28000\n",
      "  52000  44000  60500  55000  53000  40000  35500  15000  97200  36000\n",
      "  13500   2450  50000  48660  20000  45000 147000  51000   1000  66000\n",
      "  49000  37000  15487  46000  33000  52800  71200  75000  12000 150000\n",
      "  37518  70000   3528   3350  34000  43000   2875  62500  23000  68000\n",
      "  57000  39000  21000  24530  30000  41000  47000  25000  90000  29685\n",
      "  60000  48006  72000   6020  32000  48247   8000  63000 100000  48008\n",
      "  11523  25500   9000  13349  85455  14000  58000  29000  88000  26500\n",
      "   2000   3000  48000   3200     60   7500  13000  27000  97000  22000\n",
      "  60123   5000 111111  49800]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['kms_driven'].unique())\n",
    "print(df_test['kms_driven'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e4560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eeb5a2f",
   "metadata": {},
   "source": [
    "**5) fuel_type >>**\n",
    "\n",
    "    a) We need to take care of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa797791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[~df_train['fuel_type'].isna()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdaa45c",
   "metadata": {},
   "source": [
    "Since there was NaN value present in the df_train['fuel_type'], hence I select those values whose are not same as NaN values by using '~' this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e331eeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, company, year, Price, kms_driven, fuel_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['fuel_type'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d97aef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, company, year, Price, kms_driven, fuel_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['fuel_type'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d643e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "163d6b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 647 entries, 29 to 355\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        647 non-null    object\n",
      " 1   company     647 non-null    object\n",
      " 2   year        647 non-null    int64 \n",
      " 3   Price       647 non-null    int64 \n",
      " 4   kms_driven  647 non-null    int64 \n",
      " 5   fuel_type   647 non-null    object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 35.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89454f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 169 entries, 347 to 484\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        169 non-null    object\n",
      " 1   company     169 non-null    object\n",
      " 2   year        169 non-null    int64 \n",
      " 3   Price       169 non-null    int64 \n",
      " 4   kms_driven  169 non-null    int64 \n",
      " 5   fuel_type   169 non-null    object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fc218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe3438ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>647.000000</td>\n",
       "      <td>6.470000e+02</td>\n",
       "      <td>647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2012.406491</td>\n",
       "      <td>4.093243e+05</td>\n",
       "      <td>47444.238022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.974394</td>\n",
       "      <td>5.027703e+05</td>\n",
       "      <td>35986.043894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.750000e+05</td>\n",
       "      <td>27000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>2.990000e+05</td>\n",
       "      <td>41800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>4.825000e+05</td>\n",
       "      <td>59000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>8.500003e+06</td>\n",
       "      <td>400000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year         Price     kms_driven\n",
       "count   647.000000  6.470000e+02     647.000000\n",
       "mean   2012.406491  4.093243e+05   47444.238022\n",
       "std       3.974394  5.027703e+05   35986.043894\n",
       "min    2000.000000  3.000000e+04       0.000000\n",
       "25%    2010.000000  1.750000e+05   27000.000000\n",
       "50%    2013.000000  2.990000e+05   41800.000000\n",
       "75%    2015.000000  4.825000e+05   59000.000000\n",
       "max    2019.000000  8.500003e+06  400000.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d2f75",
   "metadata": {},
   "source": [
    "Here What I observed statistic values of df_train[Price], \n",
    "\n",
    "Mean value >> 4,09,324\n",
    "\n",
    "\n",
    "minimum price value >> 30,000\n",
    "\n",
    "\n",
    "25% Price values are below than >> 1,75,000\n",
    "\n",
    "\n",
    "50% Price values are below than >> 2,99,000\n",
    "\n",
    "\n",
    "75% Price values are below than >> 4,82,000\n",
    "\n",
    "\n",
    "Maximum Price value >> 85,00,000\n",
    "\n",
    "\n",
    "It seems to be outlier for such a data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "634ebb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>1.690000e+02</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2012.591716</td>\n",
       "      <td>4.208802e+05</td>\n",
       "      <td>41801.254438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.119371</td>\n",
       "      <td>3.511438e+05</td>\n",
       "      <td>26486.924239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1995.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.800000e+05</td>\n",
       "      <td>25500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.350000e+05</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>5.500000e+05</td>\n",
       "      <td>53000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.891111e+06</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year         Price     kms_driven\n",
       "count   169.000000  1.690000e+02     169.000000\n",
       "mean   2012.591716  4.208802e+05   41801.254438\n",
       "std       4.119371  3.511438e+05   26486.924239\n",
       "min    1995.000000  3.000000e+04       0.000000\n",
       "25%    2011.000000  1.800000e+05   25500.000000\n",
       "50%    2013.000000  3.350000e+05   40000.000000\n",
       "75%    2015.000000  5.500000e+05   53000.000000\n",
       "max    2019.000000  1.891111e+06  150000.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bff6a7",
   "metadata": {},
   "source": [
    "In the test data, We could see max() value above than 85 lakh, which seems to be outlier, We will remove this Outlier from the dataset by taking all the values except this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2b157ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Mahindra XUV500 W6</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2014</td>\n",
       "      <td>8500003</td>\n",
       "      <td>45000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name   company  year    Price  kms_driven fuel_type\n",
       "562  Mahindra XUV500 W6  Mahindra  2014  8500003       45000    Diesel"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[(df_train['Price']>=8.500003e+06)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c77b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.loc[(df_train['Price']<8.500003e+06)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "632ead0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train size:  (646, 6)\n",
      "df_test size:  (169, 6)\n"
     ]
    }
   ],
   "source": [
    "print('df_train size: ',df_train.shape)\n",
    "print('df_test size: ',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7cac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f77c7760",
   "metadata": {},
   "source": [
    "### Checking all the integer attributes and categorical attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f46c0dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 646 entries, 29 to 355\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        646 non-null    object\n",
      " 1   company     646 non-null    object\n",
      " 2   year        646 non-null    int64 \n",
      " 3   Price       646 non-null    int64 \n",
      " 4   kms_driven  646 non-null    int64 \n",
      " 5   fuel_type   646 non-null    object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bff779",
   "metadata": {},
   "source": [
    "#### we have successfully converted \"Year, Price, kms_driven\" attributes into Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530956a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd09ca6f",
   "metadata": {},
   "source": [
    "#### Reset Index Column for Training and Testind Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1122e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8575a4b",
   "metadata": {},
   "source": [
    "Here I reset the index number for both the dataset and saved them inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b65333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c01056cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahindra Bolero DI</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2017</td>\n",
       "      <td>180000</td>\n",
       "      <td>23452</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mitsubishi Pajero Sport</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>2015</td>\n",
       "      <td>1475000</td>\n",
       "      <td>47000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maruti Suzuki Ertiga</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2016</td>\n",
       "      <td>635000</td>\n",
       "      <td>29000</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ford Fiesta SXi</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2009</td>\n",
       "      <td>250000</td>\n",
       "      <td>56400</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan Terrano XL</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>2015</td>\n",
       "      <td>499999</td>\n",
       "      <td>60000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>Force Motors Force</td>\n",
       "      <td>Force</td>\n",
       "      <td>2015</td>\n",
       "      <td>580000</td>\n",
       "      <td>3200</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Toyota Etios</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>2011</td>\n",
       "      <td>275000</td>\n",
       "      <td>36000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Renault Duster 85</td>\n",
       "      <td>Renault</td>\n",
       "      <td>2013</td>\n",
       "      <td>489999</td>\n",
       "      <td>27000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Hyundai Xcent Base</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2016</td>\n",
       "      <td>300000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>Hyundai Verna</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2014</td>\n",
       "      <td>489999</td>\n",
       "      <td>44000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name     company  year    Price  kms_driven fuel_type\n",
       "0         Mahindra Bolero DI    Mahindra  2017   180000       23452    Diesel\n",
       "1    Mitsubishi Pajero Sport  Mitsubishi  2015  1475000       47000    Diesel\n",
       "2       Maruti Suzuki Ertiga      Maruti  2016   635000       29000    Petrol\n",
       "3            Ford Fiesta SXi        Ford  2009   250000       56400    Petrol\n",
       "4          Nissan Terrano XL      Nissan  2015   499999       60000    Diesel\n",
       "..                       ...         ...   ...      ...         ...       ...\n",
       "641       Force Motors Force       Force  2015   580000        3200    Diesel\n",
       "642             Toyota Etios      Toyota  2011   275000       36000    Diesel\n",
       "643        Renault Duster 85     Renault  2013   489999       27000    Diesel\n",
       "644       Hyundai Xcent Base     Hyundai  2016   300000      140000    Diesel\n",
       "645            Hyundai Verna     Hyundai  2014   489999       44000    Diesel\n",
       "\n",
       "[646 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7dd13ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>Price</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hyundai Grand i10</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2017</td>\n",
       "      <td>524999</td>\n",
       "      <td>6821</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Suzuki Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2016</td>\n",
       "      <td>270000</td>\n",
       "      <td>38000</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevrolet Beat LS</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>2014</td>\n",
       "      <td>189000</td>\n",
       "      <td>31000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun Go Plus</td>\n",
       "      <td>Datsun</td>\n",
       "      <td>2016</td>\n",
       "      <td>285000</td>\n",
       "      <td>13900</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mahindra Scorpio S10</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2015</td>\n",
       "      <td>395000</td>\n",
       "      <td>35000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Mitsubishi Pajero Sport</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>2015</td>\n",
       "      <td>1725000</td>\n",
       "      <td>37000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Maruti Suzuki Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2015</td>\n",
       "      <td>230000</td>\n",
       "      <td>5000</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Tata Manza ELAN</td>\n",
       "      <td>Tata</td>\n",
       "      <td>2010</td>\n",
       "      <td>155555</td>\n",
       "      <td>111111</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Mahindra XUV500 W10</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2018</td>\n",
       "      <td>1299000</td>\n",
       "      <td>40000</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Mahindra XUV500 W6</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2013</td>\n",
       "      <td>548900</td>\n",
       "      <td>49800</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name     company  year    Price  kms_driven fuel_type\n",
       "0          Hyundai Grand i10     Hyundai  2017   524999        6821    Petrol\n",
       "1         Maruti Suzuki Alto      Maruti  2016   270000       38000    Petrol\n",
       "2          Chevrolet Beat LS   Chevrolet  2014   189000       31000    Diesel\n",
       "3             Datsun Go Plus      Datsun  2016   285000       13900    Petrol\n",
       "4       Mahindra Scorpio S10    Mahindra  2015   395000       35000    Diesel\n",
       "..                       ...         ...   ...      ...         ...       ...\n",
       "164  Mitsubishi Pajero Sport  Mitsubishi  2015  1725000       37000    Diesel\n",
       "165       Maruti Suzuki Alto      Maruti  2015   230000        5000    Petrol\n",
       "166          Tata Manza ELAN        Tata  2010   155555      111111    Petrol\n",
       "167      Mahindra XUV500 W10    Mahindra  2018  1299000       40000    Diesel\n",
       "168       Mahindra XUV500 W6    Mahindra  2013   548900       49800    Diesel\n",
       "\n",
       "[169 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe01f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f0a57c",
   "metadata": {},
   "source": [
    "##  Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89e176",
   "metadata": {},
   "source": [
    "### Seperating Features and Target Lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b849f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['Price'],axis=1)\n",
    "y_train = df_train['Price']\n",
    "\n",
    "X_test =df_test.drop(['Price'],axis=1)\n",
    "y_test = df_test['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546eded",
   "metadata": {},
   "source": [
    "X_train = df_train.drop(['Price'],axis=1) >> this will drop the 'price' attribute and pass all the Independent attributes to the X_train\n",
    "\n",
    "y_train = df_train['Price'] >> will assign only dependent attribute ('price' variable) to y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "164f04e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (646, 5)\n",
      "y_train shape:  (646,)\n",
      "x_test shape:  (169, 5)\n",
      "y_test shape:  (169,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ',X_train.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "\n",
    "print('x_test shape: ',X_test.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3d731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7447f8a1",
   "metadata": {},
   "source": [
    "### Encoding Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "491e6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc= OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train)\n",
    "\n",
    "X_train= enc.transform(X_train)\n",
    "\n",
    "X_test=enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c38a7e",
   "metadata": {},
   "source": [
    "Here, I've used the OneHotEncode Class to build a single Object (enc). I then only fit my \"enc\" using the data from X train, not the entire dataset or X test. Here, \"enc\" Object used a training dataset to learn how to encode categorical properties.\n",
    "\n",
    "\n",
    "I then use the enc.transform(data) method to transform my X train and X test.\n",
    "\n",
    "Now that we have checked, my X train's size has changed from (646, 5) to (646, 492)\n",
    "\n",
    "additionally, it updated for X test from (169, 5) to (169, 492).\n",
    "\n",
    "\n",
    "If handle unknown='error' had been used, If one categorical characteristic in our X test in our X test has a new value that was not present in the X train. If an unknown category is present during the transform, OneHotEncoder will then raise an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d03f9",
   "metadata": {},
   "source": [
    "As is well known, only numerical features can be used by machine learning algorithms. It is unable to comprehend categorical features. \"Nominal Categorical Features\" are shown here.\n",
    "\n",
    "We so employed the OneHotEncoder method. It utilizes categorical variables to operate.\n",
    "Each binary unique value will be added by OneHotEncoder to your categorical characteristics.\n",
    "\n",
    "Depending on how many distinct values there are in the original categorical attribute, it will produce new attributes.\n",
    "\n",
    "Here, 6 traits were changed into 492 attributes. Our dimensionality has been expanded here in accordance with our category variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e2b9d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (646, 492)\n",
      "x_test shape:  (169, 492)\n",
      "\n",
      "y_train shape:  (646,)\n",
      "y_test shape:  (169,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ',X_train.shape)\n",
    "print('x_test shape: ',X_test.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print('y_train shape: ',y_train.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ead2e8",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40e3e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler(with_mean=False)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train= scaler.transform(X_train)\n",
    "\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb86d6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (646, 492)\n",
      "x_test shape:  (169, 492)\n",
      "\n",
      "y_train shape:  (646,)\n",
      "y_test shape:  (169,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ',X_train.shape)\n",
    "print('x_test shape: ',X_test.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print('y_train shape: ',y_train.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a405879",
   "metadata": {},
   "source": [
    "Here, I've used the StandardScaler Class to build a single Object (a scaler). I then only fit my \"scaler\" using the data from X train, not the entire dataset or X test. With the use of the training dataset, the \"scaler\" object in this case learned how to standardize the categorical properties.\n",
    "\n",
    "Then, I use the scaler.transform(data) method to transform my X train and X test.\n",
    "The range of my X train and X test has now changed from 0-n to 0-1, as shown if we inspect it.\n",
    "\n",
    "\n",
    "The \"Standardization\" procedure must be used; otherwise, my accuracy will suffer. So I made the decision to standardize the data here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13f09f",
   "metadata": {},
   "source": [
    "Normalization >> Normalization of your features means will bring our attributes data in range of 0 to 1.\n",
    "age 44 to 80 >> normalization >> 0.3 to 1.0\n",
    "\n",
    "\n",
    "Standardization (Z_score normalization) >> It is a Transformed version of your feature is normal distribution with \"mean == 0\" & \"standard deviation == 1\".\n",
    "Standardization = (each feature - mean of feature) / (standard deviations)\n",
    "\n",
    "\n",
    "Normalization vs Standardization >> standardization is a better default option to use.\n",
    "\n",
    "Here, I want to use supervised learning algorithm (Linear Regression Algorithm), Here I had some outliers, and most of the features are Normal distributions Hence, We used the standardization here.\n",
    "\n",
    "Here, we did Data Prepreocessing and Feature engineering on both Training dataset and Testing dataset. \n",
    "\n",
    "If we would have done the Data Prepreocessing and Feature engineering only on the \"Training Dataset\" and not on the \"Testing Dataset\" then we will confuse our ML Algorithm. \n",
    "\n",
    "e.g. If we do the \"Standardization\" on Training Dataset & not on the Testing Dataset then one of the attribute from Training dataset will have range from 0 to 1 & one of the attribute from Testing dataset will have range from 0 to 100. \n",
    "It will confuse our model and our Accuracy will be less.\n",
    "\n",
    "Hence we did the Data Prepreocessing and Feature engineering on both Training dataset and Testing dataset.\n",
    "\n",
    "We Impute missing values on both the dataset, we did the \"Standardization\" on both the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10720d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff4943a0",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a3ae958",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca= PCA(n_components=30)\n",
    "pca.fit(X_train.toarray())\n",
    "\n",
    "X_train= pca.transform(X_train.toarray())\n",
    "\n",
    "X_test= pca.transform(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fdc390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (646, 30)\n",
      "x_test shape:  (169, 30)\n",
      "\n",
      "y_train shape:  (646,)\n",
      "y_test shape:  (169,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ',X_train.shape)\n",
    "print('x_test shape: ',X_test.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print('y_train shape: ',y_train.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abb2d9",
   "metadata": {},
   "source": [
    "I've used the PCA Class to construct a single object here, called pca. As we are aware, the PCA algorithm is used to transform datapoints from one 492nd dimensional space to another 492nd dimensional space characteristics. The \"n components=30\" command was used after this modification to specify that I wanted to maintain the \"30 best Principle Component with Highest Variance\" features for my dataset.\n",
    "\n",
    "I then fitted my \"PCA\" using only the data from the X train and not the entire dataset or X test. With the use of the training dataset, the \"PCA\" object learned how to \"Dimensionality Reduction\" categorical attributes.\n",
    "\n",
    "Then, I use the scaler.transform(data) method to transform my X train and X test.\n",
    "In this case, it reduced 492 attributes to 30 attributes. In this case, we reduced the dimensionality without losing any important data.\n",
    "\n",
    "Since Scikit-Learn uses compressed technique to store a such high dimensional data, I also use the \"X train.toarray()\" methode to convert dataframe to Numpy Array in this case. After doing the OnHotEncoding, We will attain Higher Dimensionality of our Attributes. However, PCA class cannot handle such a large amount of data; it issues an error and instructs us to transform the enormous Dimensional data into a regular array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571a2e9",
   "metadata": {},
   "source": [
    "Diminishing Dimensions After OneHotEncoding, our dataset contained 492 features in this case.\n",
    "\n",
    "Manifolding of feature selection projection.\n",
    "\n",
    "It is known as the \"Curse of Dimensionality\" if we train our machine learning algorithm with such a high level of dimensionality because it would slow down processing time and lead to overfitting problems.\n",
    "\n",
    "\n",
    "\n",
    "We implement the \"Dimensional reduction\" to get over this issue. Compression of the data is referred to as dimensionality reduction. For instance, when we convert a PNG file to a JPG file, but compress it so that we lose some information from the dataset, it is not a big deal.\n",
    "\n",
    "Dimensionality reduction will hasten the processing of the ML algorithm. Additionally, as we reduced the dimensionality of the data, it aids with data visualization.\n",
    "However, when we reduce the dimensions, we sometimes lose information, which could result in slightly worse performance with less accuracy.\n",
    "\n",
    "\n",
    "So I used the PCA (Principle Component Analysis) algorithm to accomplish that. It basically entails projecting data points from one \"Dth Dimensional Space\" to another \"Dth Dimensional Space\" in order to reduce the dimensionality of the data.\n",
    "\n",
    "\n",
    "The PCA algorithm will attempt to determine the principal components that have orthogonal dimensions and produce the \"Highest Variance\" of the data after projection from a higher dimensional dataset.\n",
    "\n",
    "The \"First Principle Component with Highest Variance,\" the \"Second Principle Component with Highest Variance,\" and the \"ith Principle Component with Highest Variance,\" which is orthogonal to the \"First Principle Component,\" will all be found. This process will carry on until there are exactly as many dimensions as there were in original space. The subset of these Principle Components will be chosen after finding all of them (i.e. C1, C2, C3, C4). We have here decreased the dataset's dimension from Dth Space to 4th Space.\n",
    "\n",
    "In order to maintain the maximum variance of the original dataset, PCA will locate the line or hyperplane in a lower-dimensional space.\n",
    "\n",
    "\n",
    "The first axis or dimension in the lower-dimensional space that provides the greatest variance is found. This will be the first fundamental element we use (C1).\n",
    "\n",
    "The algorithm then seeks to identify the axis or dimension that lies above the initial dimensions and provides us with the greatest variance. This will be the second main element we'll use (C2).\n",
    "\n",
    "Now that the datapoints have been transformed, our model will use new features (C1, C2,..,Ci) to represent the datapoints in place of the original features (X1, X2,..,Xi).\n",
    "\n",
    "In order to limit the number of dimensions in the data, we only selected a portion of these New dimensions, i.e. (C1,C2,..Ci)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e6f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8555eca9",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410579a",
   "metadata": {},
   "source": [
    "### Algorithm Selection And Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c8e27",
   "metadata": {},
   "source": [
    "### Model_1 >> Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0f90f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LinearRegression(fit_intercept=True)\n",
    "model_1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78e08429",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a30409",
   "metadata": {},
   "source": [
    "### Model_2 >>  Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a50f49ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2= Lasso()\n",
    "model_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4de11688",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9501ea",
   "metadata": {},
   "source": [
    "### Model_3 >>  KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1417d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(metric='manhattan')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = KNeighborsRegressor(n_neighbors=5,metric='manhattan')\n",
    "model_3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d29e70c",
   "metadata": {},
   "source": [
    "### Model_4 >> Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd6a8e",
   "metadata": {},
   "source": [
    "#### Without Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1959ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4= DecisionTreeRegressor(criterion='mse',max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20ac6a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3789ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90df943d",
   "metadata": {},
   "source": [
    "#### With Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a51d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grids = {'criterion': ['mse', 'mae'],\n",
    "                  'max_depth' : [2,4,8,10,12,None],\n",
    "                   'max_features':[0.25,0.5,1.0],\n",
    "                  'min_samples_split' : [0.25,0.5,1.0],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65fb96",
   "metadata": {},
   "source": [
    "Here, We have defined the dictionary of Grid of Hyperparameter for Decision Tree Regressor.\n",
    "Here, most important Hyperparameter for Decision Tree Regressor is,\n",
    "criterion, max_depth, min_samples_split (minimun sample in one node to split it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8138ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = GridSearchCV(DecisionTreeRegressor(),\n",
    "                      param_grid=parameter_grids,\n",
    "                       scoring='r2',\n",
    "                      cv=5,\n",
    "                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d2d0f",
   "metadata": {},
   "source": [
    "A GridSearchCV is this (Grid Search Cross Validation Model). The model (DecisionTreeRegressor()), parameter grids, scoring (the main metric I want to improve is the r2 score), CV (Cross Validation with 5-fold), and n jobs (the number of jobs >> As this method is time-consuming and we must train many models with each combination of these Hyperparameter, we are employing all CPU cores to conduct the parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "755591ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae'],\n",
       "                         'max_depth': [2, 4, 8, 10, 12, None],\n",
       "                         'max_features': [0.25, 0.5, 1.0],\n",
       "                         'min_samples_split': [0.25, 0.5, 1.0]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe97208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b44a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd11b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14e27113",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9aaf57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score of Linear Regression Model:  55.23458203757061 %\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_1= model_1.predict(X_test)\n",
    "R2_score_1=r2_score(y_test, y_test_predict_1)\n",
    "print('R2_score of Linear Regression Model: ',R2_score_1*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f34a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5e963e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score of Lasso Regression  Model:  55.2344234318771 %\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_2= model_2.predict(X_test)\n",
    "R2_score_2=r2_score(y_test, y_test_predict_2)\n",
    "print('R2_score of Lasso Regression  Model: ',R2_score_2*100,'%')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8541bd40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0aec1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score of KNN Regression  Model:  51.71066173911394 %\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_3=model_3.predict(X_test)\n",
    "R2_score_3=r2_score(y_test, y_test_predict_3)\n",
    "print('R2_score of KNN Regression  Model: ',R2_score_3*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc9a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f18ac750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Without Hyperparameter Tunning\n",
      "\n",
      "Decision Tree Regressor R2_Score:  29.567111000110113 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Regressor Without Hyperparameter Tunning\\n\")\n",
    "\n",
    "y_test_predict_4= model_4.predict(X_test)\n",
    "R2_score_4=r2_score(y_test, y_test_predict_4)\n",
    "print('Decision Tree Regressor R2_Score: ',R2_score_4*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7bbec123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor With Hyperparameter Tunning\n",
      "\n",
      "\n",
      "Best Hyperparameters Values: {'criterion': 'mae', 'max_depth': 10, 'max_features': 0.5, 'min_samples_split': 0.25}\n",
      "\n",
      "Decision Tree Regressor R-Squared on Train:  45.96 %\n",
      "\n",
      "Decision Tree Regressor R2_Score on Test:  25.524443408455145 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Regressor With Hyperparameter Tunning\\n\")\n",
    "\n",
    "print(\"\\nBest Hyperparameters Values:\",model_5.best_params_)\n",
    "print(\"\\nDecision Tree Regressor R-Squared on Train: \",round((model_5.best_score_)*100,2), '%')\n",
    "\n",
    "y_test_predict_5= model_5.predict(X_test)\n",
    "R2_score_5=r2_score(y_test, y_test_predict_5)\n",
    "print('\\nDecision Tree Regressor R2_Score on Test: ',R2_score_5*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6df1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0404a09",
   "metadata": {},
   "source": [
    "# Conculusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78da86",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a38913",
   "metadata": {},
   "source": [
    "Feature Importance Analysis >> Here we have found that only 2 feature were linearly correlated with the depeendant varible.\n",
    "\n",
    "        Dependent Attribute >> Price \n",
    "        Independent Attribute >> year & kms_driven\n",
    "        \n",
    "   We all know that if an automobile was purchased recently, its selling price will be high. Therefore, the same positive link between year and price has been seen here. This relationship enables us to improve our pipeline's R2 score and obtain a lower error rate.\n",
    "\n",
    "\n",
    "As is common knowledge, the price of an automobile increases with the amount of miles it has been driven. The cost of the car will decrease as it is driven more frequently. Therefore, the same link between \"kms drive\" and \"Car Price\" has been found here; they are both inversely proportional to one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe23d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48f121a1",
   "metadata": {},
   "source": [
    "### Model Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc1d38",
   "metadata": {},
   "source": [
    "#### Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd09434",
   "metadata": {},
   "source": [
    "Linear Regression is the \"Supervised Machine Learning algorithm\". Model finds the best fit linear line between the dependent and one or more independent variables. It has two types: Simple Linear Regression and Multiple Linear Regression.\n",
    "\n",
    "Simple Linear Regression is where only one independent variable is present and the model has to find the linear relationship of it with the dependent variable. \n",
    "\n",
    "Equation for Linear Regression: y=b0+b1x\n",
    "\n",
    "Equation for Muliple Linear Regression: y=b0+b1x1+b2x2+...+bdxd\n",
    "\n",
    "We have got the highest R2_Score in Linear Regression Algorithm. Hence we are finalizing the same for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bc935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86d6fc36",
   "metadata": {},
   "source": [
    "#### Lasso Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc3c49",
   "metadata": {},
   "source": [
    "LASSO (Least Absolute Shrinkage Selector Operator) also called as L1 Regularization technique to avoid equation become to complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c63b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c4199e",
   "metadata": {},
   "source": [
    "#### KNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2cf620",
   "metadata": {},
   "source": [
    "KNN algorithm used for both regression problems and classification problems. It uses â€˜feature similarityâ€™ to predict the values of any new data points. This means that the new point is assigned a value based on how closely it resembles the points in the training set.\n",
    "Distance between the new point and each training points can be calculated using below three techniques \n",
    "\n",
    "- Manhattan (for continuous)-\n",
    "- Hamming distance (for categorical).\n",
    "- Euclidian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9966af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1be1b7",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2027c8",
   "metadata": {},
   "source": [
    "Decision tree is the versatile ML model capable of performing both regression related & classification-related task and even work in case of tasks which has multiple outputs. Decision Tree is powerful algorithms, capable of fitting even complex datasets. It is also the fundamental components of Random Forests, which is one of the most powerful machine learning algorithms available today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266c231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19142f48",
   "metadata": {},
   "source": [
    "### Bias-variance trade off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6098d5",
   "metadata": {},
   "source": [
    "\n",
    "bias-variance trade off >> the ML Model has 3 types of errors namely, \n",
    "    Bias Error\n",
    "    Variance Error\n",
    "    Irreducible Error\n",
    "    \n",
    "Irreducible Error is not about the model, it is about the data. Our model is not accurate because our data is not accurate. Here, I checked the correlation of each feature attributes with the lable variable and it's not linear.\n",
    "\n",
    "Here, We can't change the error by changing the model Hence It is called as \"Irreducable Error\".\n",
    "\n",
    "Yes, but we try to optimize the error by doing data preprocessing.\n",
    "\n",
    "\n",
    "Bias error and Variance Error are depend on the ML Algorithm that we select.\n",
    "And depending on the complexity of our model we got High Bias & High Variance Error.\n",
    "\n",
    "\n",
    "Bias >> Direction (Centre, Right, left, top, Bottom) of the quardinate\n",
    "Variance >> distance between datapoints\n",
    "\n",
    "Low bias >> data points are at center of the quardinate\n",
    "High Bias >> data points are at any particular direction of the quardinate\n",
    "\n",
    "Low Variance >> all datapoints are close to each other\n",
    "High Variance >> all datapoints are away from each other.\n",
    "\n",
    "We were aiming for the model which has Low Bias and Low variance.\n",
    "\n",
    "Bias error happens >> due to simplicity of the model, if model is too simple then model can't lear the data perfectly. Hence, Model become too bias, Model didn't have enough power to learn the data.\n",
    "\n",
    "If the Feature data is not linear data, and if we use LinearRegression() here, then we get high bias error. Model makes a wrong assumption about the data. LinearRegression will not fit completly. Model will assume that data is too simple and linear, accordingly it predict the price, but this is not the case. Our data is a complex data and its not a linear data, hence we are getting high bias error.\n",
    "\n",
    "\n",
    "Variance >> If our model is too complex then we get the Variance error. If our model is too complex then it always tries to catch the each and every data points, and this model becomes 'train_data specific model' and gives High Accuracy on the training dataset. Here, Problem is, This model can't generalize the data points, Althoguh this model is so complex and learnt the training data set perfectly,But when new dataset (X_test) feed to this model, then Model cant predict accurately. \n",
    "\n",
    "So, we tried to build a righ model with right level of complexity which offers a \"Low-Bias Error\" & \"Low-Variance Error\" and Total error which sum of \"Bias error\" and \"Variance error\" should be minumum. This is called as \"Bias-Variance Trade-Off\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f77251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "352f9def",
   "metadata": {},
   "source": [
    "### Overfitting and Underfitting Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963bb34a",
   "metadata": {},
   "source": [
    "\n",
    "As we know that, \"Bias & Variance\" both term came from \"Statistics\", but in \"Machine Learning\" we have \"Underfitting & Overfitting\".\n",
    "\n",
    "When our model is too simple then we called it as \"High Bias Error\" or \"Underfitting\" >> Model underfits the training data points. Model can't able to learn the data perfectly. \n",
    "Here we train our model using df_train and this model does not able perform well neither on df_train nor on df_test dataset. So this is called as \"Underfitting\" \n",
    "\n",
    "To deal this \"Underfitting\" issue we used the more complex models like \"Lasso Regressor\", \"DecisionTreeRegressor\" & \"KNN Regressor\". \n",
    "Here, we are tried to get more correlated features & informative features with the target lables. We made our model complex by tunning some \"Hyperparameters\"\n",
    "\n",
    "\n",
    "When our model is too complex then we called it as \"High Variance Error\" or \"Overerfitting\" >> model overfits the training data points.\n",
    "\n",
    "Here we train our model using df_train and this model performed well only on df_train but when we evaluate on df_test dataset it doesn't perforemd well. So this is called as \"Overfitting\" \n",
    "\n",
    "If the Overfitting problem had been there, then we would have used below technique to solve the issue:\n",
    "\n",
    "    1) Simplify Model:- As our model is too complex like Deep Learning Model, then we will use simple model like (decision tree, svm etc.)\n",
    "    \n",
    "    2) If the dataset has some noises/outliers in the data, then we will remove those noises/outliers from it. Otherwise, Since our model is too complex then complex model will try to learn these noises/Outliers and treat it as a Patterns.\n",
    "    \n",
    "    3) If possible We will feed more training dataset to our model to solve the overfitting issue.\n",
    "    \n",
    "    4) We will do dimensionality reduction to avoid the Overfitting issue.\n",
    "\n",
    "  ***5) We will do the \"Regularization\" approch to avoid the Overfitting issue *** We will put constrain on our Machine Learning model and will not allow our model to become to complex is called as \"Regularization\".\n",
    "  \n",
    "    As we know in DecisionTree algorithm, We have hyperparameter \"max_depths\",\n",
    "if we do not set any particual integer value to this hyperparameter, then our tree become larger and larger and it will predict lable of every point accuretly. So, this complex model will overfit the data. \n",
    "    \n",
    "    To avoid overfitting issue, we set a hyperparameter of the DecisionTree model (\"max_depths\") to regularize the tree. So, this becomes a \"Regularization Hyperparameter\" to put constrain on the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc9069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5bff8e",
   "metadata": {},
   "source": [
    "### L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae178a68",
   "metadata": {},
   "source": [
    "\"L1 and L2 Regularization\" >> The method is to add second term (C|w|) to the objective function to penalize the if it has lots of parameters.\n",
    "Goal is to stop our model becoming too complex. We can do this by reduceing the parameters of the model.\n",
    "\n",
    "As we know that, every ML algorithm has its own formula, then we define the objective function to find the best value of the parameter of the model. We can find best value of parameter by Minimizing or Maximizing the Objective function.\n",
    "\n",
    "second term (C|w|) >>\n",
    "    C   >> coefficient\n",
    "    \n",
    "    |w| >> L1 norm of parameter vector >> sigma over all absolute of weights \n",
    "\n",
    "C >> hyperparameter and \"C\" controls regularization of the model.\n",
    "\n",
    "L1 Regularization: \n",
    "    MSE= ((summ(Yi - Yp)**2) + C|w|) / N\n",
    "                      \n",
    "if we put C|w|=0, then second term will be removed and we get our orignal objective function, \n",
    "\n",
    "As our goal is to put some constrain on our model and stop the model from becoming to complex. For that we have reduced some parameters in order to simplify the model.\n",
    "\n",
    "So,Initially we have all the d+1 parameters,\n",
    "To simplify our model we trained our model so that model will not use all the parameters of the objective function, it will set some of them as \"Zero\" or close to \"Zero\". This is how we simplified our model. So for that, by adding \"C|w|\" this term model get penalize if it gets many \"non-zero\" parameters.\n",
    "\n",
    "if C|W| is \"High\" means model is using all the parameters of the objective function. \n",
    "\n",
    "if C|W| is \"Low\" means model is seting some of the parameters of the objective function equal to zero. And number of parameter of our model is reduced and now model is become simplifed.\n",
    "L1 Regularization is also called as \"Lasso Regression\"\n",
    "\n",
    "L2 Regularization: \n",
    "    MSE= ((summ(Yi - Yp)**2) + C||w||**2) / N\n",
    "                      \n",
    "C   >> coefficient\n",
    "|w| >> L2 norm of parameter vector >> sigma of all weights of power of 2   L2 \n",
    "Regularization is also called as \"Ridge Regression\" \n",
    "\n",
    "We should use Regularization technique to avoid \"Overfitting\" issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6420dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ef0bd93",
   "metadata": {},
   "source": [
    "### Strength Weaknesses of our Pipeline & Recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf568b",
   "metadata": {},
   "source": [
    "Reasons to get less accuracy?\n",
    "\n",
    "    1) Features are not Informative\n",
    "\n",
    "    2) Less Feature Attributes\n",
    "    \n",
    "    3) Less data samples\n",
    "    \n",
    "    4) Less correlation between Independent and Dependant Variables\n",
    "    \n",
    "    2) Data is Noisy\n",
    "    \n",
    "    3) Data errors\n",
    "    \n",
    "    4) Wrong Model\n",
    "    \n",
    "    5) Hyperparameters are not well tunned\n",
    "    \n",
    "Here I have carefully analyzed all this thing and I did experiment on all those points, and able achieve the best R2_score for that.\n",
    "\n",
    "Strength Weaknesses of Our Pipeline:- \n",
    "\n",
    "   Strength >>\n",
    "        Here we have used all the techniques which generalize our model for all the data points.\n",
    "        We permform operations like \n",
    "        \n",
    "            \"Encoding categorical Attributes using OneHotEncoder\"\n",
    "            \n",
    "            \"Standardization on the data so that they are in same range\"\n",
    "            \n",
    "            \"Dimensionality reduction Using PCA (Principle Component Analysis) so that we can have the features with Highest                Variance\"\n",
    "            \n",
    "            \"We trained our model with different algorithms like (Linear Regression, Lasso Regression, KNN Regression,                      DecisionTreeRegressor)\"\n",
    "            \n",
    "            \"We performed the Hyper-Parameter tunning to optimize the model\"\n",
    "            \n",
    "            \"We evaluate our model using Test dataset for all the algorithm\"\n",
    "            \n",
    "            \"We got R2_score for each model\"\n",
    "            \n",
    "\n",
    "\n",
    "   Weakness >>\n",
    "           Here It has been obeserved data, we got the error of \"Irreducible Error\". Our model is perfectly designed, pipeline            is perfectly fitted, but Our data has some issues. We tried to optimized the issues and successed in the some. But              below are the some observations that i would like to highlight here,\n",
    "           \n",
    "            \"Features are not Informative\"\n",
    "            \n",
    "            \"Less Feature Attributes\"\n",
    "            \n",
    "            \"Less data samples\"\n",
    "            \n",
    "            \"Less correlation between Independent and Dependant Variables\"\n",
    "            \n",
    "            \"Data is Noisy\"\n",
    "            \n",
    "            \"Data errors\"\n",
    "            \n",
    "            \n",
    "Recommendation >> If our Domain Experty & Data Analyst team do the better disscussion with client and get the features/data which are relevent to get the better performance then we will get the better accuracy for this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3aa596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e72b3167",
   "metadata": {},
   "source": [
    "### References "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb90961",
   "metadata": {},
   "source": [
    "Below are the resources to learn more about the dataset and tools:\n",
    "\n",
    "Dataset: https://drive.google.com/drive/folders/1fHtEcXuY-tCnbNvMNtM8t1TcE6hT7Sg7?usp=sharing\n",
    "\n",
    "Pandas user guide: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "\n",
    "Matplotlib user guide: https://matplotlib.org/3.3.1/users/index.html\n",
    "\n",
    "Seaborn user guide & tutorial: https://seaborn.pydata.org/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5088fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
